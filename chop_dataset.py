# This script outputs a CSV at `OUT_CSV_PATH` for training over a slimmed version of the Expanded Groove MIDI Dataset.
# (See `create_slim_metadata.py` for details on the slimmed dataset.)
# It assumes the dataset has been downloaded and extracted to `dataset/e-gmd-v1.0.0`,
# and that the metadata file `dataset/e-gmd-v1.0.0-slim.csv`, generated by the `create_slim_metadata.py` script, is present.
#
# It consists of a row per "drum hit", which is composed of one or more simultaneously sounding drum instruments, and it has the following columns:
# - `file_path`: The path to the audio file in the E-GMD dataset.
# - `begin_frame`: The frame (sample index) of the beginning of the hit.
# - `num_frames`: The length, in frames, of the hit.
# - `labels`: A space-separated list of drum instrument labels, corresponding to the `id` column in the
#             `dataset/label_mapping.csv` file generated by the `create_label_mapping.py` script.

from mido import MidiFile
import pandas as pd

DATASET_DIR = 'dataset/e-gmd-v1.0.0'
SLIM_METADATA_PATH = 'dataset/e-gmd-v1.0.0-slim.csv'
LABEL_MAPPING_PATH = 'dataset/label_mapping.csv'

CHOPPED_OUT_CSV_PATH = 'dataset/chopped.csv'
# Output dataset column names
FILE_PATH_COL = 'file_path'
BEGIN_FRAME_COL = 'begin_frame'
NUM_FRAMES_COL = 'num_frames'
LABELS_COL = 'labels'

# E-GMD metadata column names
DRUMMER = 'drummer'
SESSION = 'session'
ID = 'id'
STYLE = 'style'
BPM = 'bpm'
BEAT_TYPE = 'beat_type' # 'beat' or 'fill'
TIME_SIGNATURE = 'time_signature'
DURATION = 'duration'
SPLIT = 'split' # 'train', 'test', or 'validation'
MIDI_FILENAME = 'midi_filename'
AUDIO_FILENAME = 'audio_filename'
KIT_NAME = 'kit_name'

SAMPLE_RATE = 44_100

# Appends a row per "drum hit" to the provided `dataset`.
# `dataset` is expected to have the dataset columns (described above) as keys, with list values.
# A "drum hit" is a segment of audio that contains at least one drum instrument.
# `file_path` is relative to `DATASET_DIR`, excluding the file extension.
def append_records(dataset, label_mapping_df, session_metadata):
    audio_file_path = session_metadata[AUDIO_FILENAME]
    midi_file_path = f'{DATASET_DIR}/{session_metadata[MIDI_FILENAME]}'
    bpm = session_metadata['bpm']

    midi_file = MidiFile(midi_file_path)
    assert(len(midi_file.tracks) == 2) # First track is metadata, then one track of drum notes.
    midi_track = midi_file.tracks[1]

    frames_per_tick = (SAMPLE_RATE * 60) / (bpm * midi_file.ticks_per_beat) 

    # Find the drum hits. todo Needs work.
    current_hit = None

    # Adds `current_hit` to `dataset` if valid.
    def add_hit(end_frame):
        if current_hit is None:
            return

        num_frames = int(end_frame - current_hit[BEGIN_FRAME_COL])
        if num_frames <= 0:
            # print(f'Warning: Hit has non-positive length: {current_hit}')
            return

        dataset[FILE_PATH_COL].append(audio_file_path),
        dataset[BEGIN_FRAME_COL].append(current_hit[BEGIN_FRAME_COL]),
        dataset[NUM_FRAMES_COL].append(int(end_frame - current_hit[BEGIN_FRAME_COL])),
        dataset[LABELS_COL].append(current_hit[LABELS_COL])

    def get_label_id(note):
        match = label_mapping_df[label_mapping_df.note == note]
        return None if len(match) == 0 else match.iloc[0].id

    # [Roland TD-17 MIDI implementation spec](https://static.roland.com/assets/media/pdf/TD-17_MIDI_Imple_eng01_W.pdf)
    # It doesn't say this in the spec, but it seems that note off events are sent as note on events with velocity 0.
    total_ticks = 0
    for msg in midi_track:
        total_ticks += msg.time # Delta time
        is_note_on = msg.type == 'note_on' and msg.velocity > 0
        is_note_off = msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0)
        if not is_note_on and not is_note_off:
            # todo handle hi-hat pedal CC
            continue # Metadata, program change, etc.

        note = msg.note
        label_id = get_label_id(note)
        if label_id is None:
            continue # Ignore notes that aren't in the label mapping.

        frame = int(total_ticks * frames_per_tick) # Round down to nearest frame.
        if is_note_on:
            if current_hit is None:
                # Start a new hit.
                current_hit = {BEGIN_FRAME_COL: frame, LABELS_COL: set([label_id])}
            else:
                num_frames = int(frame - 1 - current_hit[BEGIN_FRAME_COL])
                if num_frames <= 100:
                    # Within the start threshold. Add the note to the current hit.
                    current_hit[LABELS_COL].add(label_id)
                else:
                    # Add the current hit, and start a new one with the old labels plus the new one.
                    add_hit(frame - 1)
                    current_hit = {BEGIN_FRAME_COL: frame, LABELS_COL: current_hit[LABELS_COL].copy() | set([label_id])}
        elif current_hit:
            # Add the current hit, remove the label from the current hit, and start a new one if there are any labels left.
            add_hit(frame - 1)
            current_hit = {BEGIN_FRAME_COL: frame, LABELS_COL: current_hit[LABELS_COL].copy() - set([label_id])}
            if len(current_hit[LABELS_COL]) == 0:
                current_hit = None

    # Add the final hit to the dataset.
    add_hit(session_metadata[DURATION] * SAMPLE_RATE)

if __name__ == '__main__':
    metadata_df = pd.read_csv(SLIM_METADATA_PATH)
    label_mapping_df = pd.read_csv(LABEL_MAPPING_PATH)
    dataset = {FILE_PATH_COL: [], BEGIN_FRAME_COL: [], NUM_FRAMES_COL: [], LABELS_COL: []}
    for i, session_metadata in metadata_df.iterrows():
        print(f'Processing {session_metadata[MIDI_FILENAME]}...')
        append_records(dataset, label_mapping_df, session_metadata)
        if i > 500:
            break # todo remove this
    
    print('')
    print(f'Saving chopped dataset of {len(dataset[FILE_PATH_COL])} rows to {CHOPPED_OUT_CSV_PATH}.')
    df = pd.DataFrame(dataset)
    df[LABELS_COL] = df[LABELS_COL].apply(lambda x: ' '.join(map(str, x))) # Convert labels to a space-separated string.
    df.to_csv(CHOPPED_OUT_CSV_PATH, index=False)
