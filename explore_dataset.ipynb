{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset/e-gmd-v1.0.0'\n",
    "slim_metadata_df = pd.read_csv('dataset/e-gmd-v1.0.0-slim.csv') # See `create_slim_metadata.py` for details.\n",
    "note_occurrences_slim_df = pd.read_csv('dataset/note_occurrences_slim.csv') # See `create_label_mappings.py` for details.\n",
    "labels_df = pd.read_csv('dataset/label_mapping.csv') # See `create_label_mappings.py` for details.\n",
    "chopped_df = pd.read_csv('dataset/chopped.csv') # See `chop_dataset.py` for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note occurrences in slim dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_occurrences_slim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Note Occurrences')\n",
    "_ = plt.bar(note_occurrences_slim_df['name'], note_occurrences_slim_df['occurrences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label mappings\n",
    "\n",
    "The top-5 most frequencly occurring drum instrument types are used for training.\n",
    "\n",
    "The label mappings contain a row for each training drum instrument, with the following columns:\n",
    "- `id`: Used for one-hot encoding during training. Corresponds to the instrument's occurrence frequency rank in the slim dataset, with the smallest value corresponding to the most common.\n",
    "- `note`: The MIDI note of the drum instrument.\n",
    "- `name`: The human-readable name of the drum instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_name = lambda label: labels_df.iloc[label]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chopped dataset\n",
    "\n",
    "The \"chopped\" dataset is the final, processed dataset used for training.\n",
    "\n",
    "It consists of a row per \"drum hit\", which is composed of one or more simultaneously sounding drum instruments, and it has the following columns:\n",
    "- `file_path`: The path to the audio file in the E-GMD dataset.\n",
    "- `begin_frame`: The frame (sample index) of the beginning of the hit.\n",
    "- `num_frames`: The length, in frames, of the hit.\n",
    "- `label`: A drum instrument label, corresponding to the `id` column in the `dataset/label_mapping.csv` file generated by the `create_label_mapping.py` script.\n",
    "- `slim_id`: The session ID (index in `e-gmd-v1.0.0-slim.csv`) in which this hit was found, for access to any other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = chopped_df.label.value_counts()\n",
    "label_counts.index = label_counts.index.map(get_name)\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Label occurrences in \"chopped\" dataset')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Occurrences')\n",
    "_ = plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def preview_record(row):\n",
    "    audio_file_path = f'{dataset_dir}/{row.file_path}'\n",
    "    sample_rate, data_int16 = wavfile.read(audio_file_path)\n",
    "    clip_data_int16 = data_int16[row.begin_frame:row.begin_frame + row.num_frames]\n",
    "    clip_data = clip_data_int16 / (2**15) # Convert from int16 to float32\n",
    "    length = clip_data.shape[0] / sample_rate\n",
    "    time = np.linspace(0, length, clip_data.shape[0])\n",
    "    label = row.label\n",
    "    name = labels_df.iloc[label]['name']\n",
    "    session = slim_metadata_df.iloc[row.slim_id]\n",
    "    kit_name = session.kit_name\n",
    "\n",
    "    plt.plot(time, clip_data, label=f'{name} ({kit_name})')\n",
    "\n",
    "    # Get the default y-axis limits (slightly larger than min and max values, which I want to keep).\n",
    "    current_axes = plt.gca()\n",
    "    y_min, y_max = current_axes.get_ylim()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, length])\n",
    "    plt.ylim([y_min, y_max]) # Need to reset ylim after adding rects to prevent further autoscaling above/below the rects.\n",
    "    plt.show()\n",
    "\n",
    "    return Audio(clip_data, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_record(chopped_df[chopped_df.label == 3].iloc[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
