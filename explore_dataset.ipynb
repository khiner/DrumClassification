{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset/e-gmd-v1.0.0'\n",
    "slim_metadata_df = pd.read_csv('dataset/e-gmd-v1.0.0-slim.csv') # See `create_slim_metadata.py` for details.\n",
    "note_occurrences_slim_df = pd.read_csv('dataset/note_occurrences_slim.csv') # See `create_label_mappings.py` for details.\n",
    "labels_df = pd.read_csv('dataset/label_mapping.csv') # See `create_label_mappings.py` for details.\n",
    "chopped_df = pd.read_csv('dataset/chopped.csv') # See `chop_dataset.py` for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note occurrences in slim dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_occurrences_slim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Note Occurrences')\n",
    "_ = plt.bar(note_occurrences_slim_df['name'], note_occurrences_slim_df['occurrences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label mappings\n",
    "\n",
    "The top-5 most frequencly occurring drum instrument types are used for training.\n",
    "\n",
    "The label mappings contain a row for each training drum instrument, with the following columns:\n",
    "- `id`: Used for one-hot encoding during training. Corresponds to the instrument's occurrence frequency rank in the slim dataset, with the smallest value corresponding to the most common.\n",
    "- `note`: The MIDI note of the drum instrument.\n",
    "- `name`: The human-readable name of the drum instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chopped dataset\n",
    "\n",
    "The \"chopped\" dataset is the final, processed dataset used for training.\n",
    "\n",
    "It consists of a row per \"drum hit\", which is composed of one or more simultaneously sounding drum instruments, and it has the following columns:\n",
    "- `file_path`: The path to the audio file in the E-GMD dataset.\n",
    "- `begin_frame`: The frame (sample index) of the beginning of the hit.\n",
    "- `num_frames`: The length, in frames, of the hit.\n",
    "- `labels`: A space-separated list of drum instrument labels, corresponding to the `id` column in the `dataset/label_mapping.csv` file generated by the `create_label_mapping.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def preview_record(row):\n",
    "    audio_file_path = f'{dataset_dir}/{row.file_path}'\n",
    "    sample_rate, data_int16 = wavfile.read(audio_file_path)\n",
    "    clip_data_int16 = data_int16[row.begin_frame:row.begin_frame + row.num_frames]\n",
    "    clip_data = clip_data_int16 / (2**15) # Convert from int16 to float32\n",
    "    length = clip_data.shape[0] / sample_rate\n",
    "    time = np.linspace(0, length, clip_data.shape[0])\n",
    "    labels = [labels_df.iloc[int(label)]['name'] for label in row.labels.split(' ')]\n",
    "\n",
    "    plt.plot(time, clip_data)\n",
    "\n",
    "    # Get the default y-axis limits (slightly larger than min and max values, which I want to keep).\n",
    "    current_axes = plt.gca()\n",
    "    y_min, y_max = current_axes.get_ylim()\n",
    "\n",
    "    # Plot background label rectangles.\n",
    "    num_labels = len(labels)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, num_labels))  # Generate colors\n",
    "    for i, label in enumerate(labels):\n",
    "        bottom = i / num_labels * (y_max - y_min) + y_min\n",
    "        top = (i + 1) / num_labels * (y_max - y_min) + y_min\n",
    "        plt.axhspan(bottom, top, color=colors[i], alpha=0.3, label=f'{label}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, length])\n",
    "    plt.ylim([y_min, y_max]) # Need to reset ylim after adding rects to prevent further autoscaling above/below the rects.\n",
    "    plt.show()\n",
    "\n",
    "    return Audio(clip_data, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_record(chopped_df.iloc[10106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
